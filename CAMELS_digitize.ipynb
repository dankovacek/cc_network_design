{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMELS Digitization\n",
    "\n",
    "Read the USGS streamflow stations from the [CAMELS dataset](https://ral.ucar.edu/solutions/products/camels), discretize the dataset based on a 3 bit (8 bin) equiprobable distribution, and write the digitized streamflow series to individual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import collections\n",
    "from multiprocessing import Pool\n",
    "\n",
    "db_path = '/media/danbot/T7 Touch/camels_db/usgs_streamflow/'\n",
    "\n",
    "folders = [f'{db_path}{f}/' for f in os.listdir(db_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve all filepaths for all streamflow files\n",
    "all_filepaths = []\n",
    "for folder in folders:\n",
    "    files = os.listdir(folder)\n",
    "    all_filepaths += [f'{folder}{e}' for e in files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniform_noise(precision, n):    \n",
    "    threshold = (10**(precision+6) / 2 - 1) / 10**(precision+7)\n",
    "    noise = np.random.uniform(-threshold, threshold, n)    \n",
    "    return np.clip(noise, a_min=0., a_max=None)\n",
    "\n",
    "\n",
    "def determine_series_precision(df):\n",
    "    n_decimals = [len(str(e).split('.')[-1]) for e in df['flow'].to_numpy()]\n",
    "    return max(n_decimals)\n",
    "\n",
    "\n",
    "def add_dummy_precision(df, label, i=0, series_precision=2):\n",
    "    # find all duplicate values and add artificial noise \n",
    "    # to allow equiprobable binning\n",
    "    \n",
    "    series_precision = determine_series_precision(df)\n",
    "    \n",
    "    repeated_vals = [item for item, count in collections.Counter(df[label].to_numpy()).items() if count > 1]\n",
    "#     print(f'{len(repeated_vals)} at iteration {i}')\n",
    "    while (i < 10) & (len(repeated_vals) != 0):\n",
    "        \n",
    "        dupe_idx = df[df[label].duplicated()].index\n",
    "        n_values = len(dupe_idx)\n",
    "        \n",
    "        df.loc[dupe_idx, label] += generate_uniform_noise(series_precision, n_values)\n",
    "        foo = generate_uniform_noise(series_precision, n_values)\n",
    "\n",
    "        i += 1\n",
    "        series_precision += 1\n",
    "        if series_precision > 3:\n",
    "            series_precision == 3\n",
    "            \n",
    "        repeated_vals = [item for item, count in collections.Counter(df[label].to_numpy()).items() if count > 1]\n",
    "\n",
    "        if len(repeated_vals) == 0:\n",
    "            return df\n",
    "        else:\n",
    "            add_dummy_precision(df, label, i, series_precision)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_equiprobable_bin_edges(df, n_bins):\n",
    "    n_obs = len(df)\n",
    "    min_q = df\n",
    "    probs = np.linspace(0.0,1, n_bins+1)\n",
    "    return st.mstats.mquantiles(df['flow'], prob=probs)\n",
    "\n",
    "\n",
    "def convert_to_datetime_str(row):\n",
    "    year = row['year']\n",
    "    month = row['month']\n",
    "    day = row['day']\n",
    "    s = f'{year}-{month}-{day}'\n",
    "    return pd.to_datetime(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(f):\n",
    "    n_bins = 128\n",
    "    df = pd.read_csv(f, sep='\\s+', header=None, names=['id', 'year', 'month', 'day', 'flow', 'flag'])\n",
    "    df['flow'] = df['flow'].clip(lower=0, upper=None)\n",
    "    \n",
    "    stn = f.split('/')[-1].split('_')[0]\n",
    "    folder = f'/media/danbot/T7 Touch/camels_db/digitized_series/{n_bins}bit/'\n",
    "    \n",
    "    if f'{stn}.csv' in os.listdir(folder):\n",
    "#         print(f'{stn} file exists.')\n",
    "        return None\n",
    "    \n",
    "    df = add_dummy_precision(df, 'flow')\n",
    "\n",
    "    if len(df[df['flow'].isna()]) > 0:\n",
    "        print(\"NULL VALUES FOUND\")\n",
    "        print(\"NULL VALUES FOUND\")\n",
    "        print(\"NULL VALUES FOUND\")\n",
    "        print(\"NULL VALUES FOUND\")\n",
    "        print(\"NULL VALUES FOUND\")\n",
    "        \n",
    "        print('')\n",
    "    \n",
    "    equiprobable_bin_edges = derive_equiprobable_bin_edges(df, n_bins)\n",
    "        \n",
    "#     print(f'For station {stn}, bin edges are {equiprobable_bin_edges}')\n",
    "    max_q = df['flow'].max()\n",
    "    min_q = df['flow'].min()\n",
    "#     print(f'    flow range: {min_q} - {max_q} cms')\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "    try:\n",
    "        df['bin_no'] = np.digitize(df['flow'], equiprobable_bin_edges[1:], right=True)\n",
    "    except ValueError as err:\n",
    "        print(f'Error at {stn}: ')\n",
    "        print(f'         {err}')\n",
    "        print(f'         {equiprobable_bin_edges}')\n",
    "        return None\n",
    "    \n",
    "#     bin_nos = list(set(df['bin_no']))\n",
    "#     print(f'    bin nos:')\n",
    "#     print(f'           {bin_nos}')\n",
    "    \n",
    "    df = df[['datetime', f'bin_no']]\n",
    "    output_filepath = f'{stn}.csv'\n",
    "    df.to_csv(folder + output_filepath, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "# pool = Pool()\n",
    "# pool.map(process_files, all_filepaths[:3])\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "\n",
    "for f in all_filepaths:\n",
    "    process_files(f)\n",
    "\n",
    "t1 = time.time()\n",
    "t_tot = t1 - t0\n",
    "print(f'Time to generate {len(all_filepaths)} files: {t_tot:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
