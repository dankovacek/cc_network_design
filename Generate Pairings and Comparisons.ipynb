{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/data_analysis/lib/python3.8/site-packages/geopandas/_compat.py:84: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paired Watershed Characteristics\n",
    "\n",
    "Develop framework to compare pairs of daily flow series from basins in the WSC database.  \n",
    "\n",
    "## Method:\n",
    "\n",
    "1. Generate a list of valid pairs of stations. A valid pair is one where:\n",
    "    * basin geometry exists for both stations\n",
    "    * there is a minimum N years of concurrent data between the two stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Number</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Province</th>\n",
       "      <th>Status</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Year From</th>\n",
       "      <th>Year To</th>\n",
       "      <th>Gross Drainage Area (km2)</th>\n",
       "      <th>Effective Drainage Area (km2)</th>\n",
       "      <th>...</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Operation Schedule</th>\n",
       "      <th>Sediment</th>\n",
       "      <th>RHBN</th>\n",
       "      <th>Real-Time</th>\n",
       "      <th>Datum Name</th>\n",
       "      <th>Publishing Office</th>\n",
       "      <th>Operating Agency</th>\n",
       "      <th>Contributed</th>\n",
       "      <th>Elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01AA002</td>\n",
       "      <td>DAAQUAM (RIVIERE) EN AVAL DE LA RIVIERE SHIDGEL</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>46.55750</td>\n",
       "      <td>-70.08111</td>\n",
       "      <td>1967</td>\n",
       "      <td>1977</td>\n",
       "      <td>598.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>347.313904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01AA004</td>\n",
       "      <td>GAUTHIER (RIVIERE) A SON EMBOUCHURE</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>46.80083</td>\n",
       "      <td>-70.13806</td>\n",
       "      <td>1975</td>\n",
       "      <td>1981</td>\n",
       "      <td>16.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Level</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AB001</td>\n",
       "      <td>BUCKLEY (RIVIERE) EN AVAL DU LAC JOHNNY</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>46.87917</td>\n",
       "      <td>-70.08750</td>\n",
       "      <td>1973</td>\n",
       "      <td>1981</td>\n",
       "      <td>6.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Level</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01AD001</td>\n",
       "      <td>MADAWASKA (RIVIÈRE) À 6 KM EN AVAL DU BARRAGE ...</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>47.54833</td>\n",
       "      <td>-68.63639</td>\n",
       "      <td>1918</td>\n",
       "      <td>2005</td>\n",
       "      <td>2690.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>143.667770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01AD002</td>\n",
       "      <td>SAINT JOHN RIVER AT FORT KENT</td>\n",
       "      <td>NB</td>\n",
       "      <td>Active</td>\n",
       "      <td>47.25806</td>\n",
       "      <td>-68.59583</td>\n",
       "      <td>1926</td>\n",
       "      <td>2018</td>\n",
       "      <td>14700.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>INTERNATIONAL BOUNDARY COMMISSION DATUM</td>\n",
       "      <td>DARTMOUTH</td>\n",
       "      <td>UNITED STATES GEOLOGICAL SURVEY</td>\n",
       "      <td>Y</td>\n",
       "      <td>158.894211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station Number                                       Station Name Province  \\\n",
       "0        01AA002    DAAQUAM (RIVIERE) EN AVAL DE LA RIVIERE SHIDGEL       QC   \n",
       "1        01AA004                GAUTHIER (RIVIERE) A SON EMBOUCHURE       QC   \n",
       "2        01AB001            BUCKLEY (RIVIERE) EN AVAL DU LAC JOHNNY       QC   \n",
       "3        01AD001  MADAWASKA (RIVIÈRE) À 6 KM EN AVAL DU BARRAGE ...       QC   \n",
       "4        01AD002                      SAINT JOHN RIVER AT FORT KENT       NB   \n",
       "\n",
       "         Status  Latitude  Longitude  Year From  Year To  \\\n",
       "0  Discontinued  46.55750  -70.08111       1967     1977   \n",
       "1  Discontinued  46.80083  -70.13806       1975     1981   \n",
       "2  Discontinued  46.87917  -70.08750       1973     1981   \n",
       "3  Discontinued  47.54833  -68.63639       1918     2005   \n",
       "4        Active  47.25806  -68.59583       1926     2018   \n",
       "\n",
       "   Gross Drainage Area (km2)  Effective Drainage Area (km2)  ... Data Type  \\\n",
       "0                     598.00                            NaN  ...      Flow   \n",
       "1                      16.60                            NaN  ...     Level   \n",
       "2                       6.94                            NaN  ...     Level   \n",
       "3                    2690.00                            NaN  ...      Flow   \n",
       "4                   14700.00                            NaN  ...      Flow   \n",
       "\n",
       "  Operation Schedule Sediment RHBN Real-Time  \\\n",
       "0         Continuous        N    N         N   \n",
       "1           Seasonal        N    N         N   \n",
       "2           Seasonal        N    N         N   \n",
       "3         Continuous        N    N         N   \n",
       "4         Continuous        N    Y         N   \n",
       "\n",
       "                                Datum Name Publishing Office  \\\n",
       "0                               ARBITRAIRE       QUEBEC CITY   \n",
       "1                               ARBITRAIRE       QUEBEC CITY   \n",
       "2                               ARBITRAIRE       QUEBEC CITY   \n",
       "3                               ARBITRAIRE       QUEBEC CITY   \n",
       "4  INTERNATIONAL BOUNDARY COMMISSION DATUM         DARTMOUTH   \n",
       "\n",
       "                         Operating Agency Contributed   Elevation  \n",
       "0  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  347.313904  \n",
       "1  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  401.000000  \n",
       "2  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  411.000000  \n",
       "3  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  143.667770  \n",
       "4         UNITED STATES GEOLOGICAL SURVEY           Y  158.894211  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import basin characteristics\n",
    "WSC_db_folder = '/media/danbot/T7 Touch/hydat_db/'\n",
    "metadata_fn = 'WSC_Stations_Master.csv'\n",
    "\n",
    "df = pd.read_csv(WSC_db_folder + metadata_fn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_years_record'] = df['Year To'] - df['Year From']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588\n"
     ]
    }
   ],
   "source": [
    "# filter for stations in BC and Alberta\n",
    "df = df[df['Province'].isin(['BC', 'AB'])]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588\n",
      "6435078\n"
     ]
    }
   ],
   "source": [
    "stn_pairs_list = list(combinations(df['Station Number'].to_numpy(), 2))\n",
    "print(len(df))\n",
    "print(len(stn_pairs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs with < 20 years overlap return as None, so filter them out\n",
    "# filtered_pairs = [e for e in overlapping_records if e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hysets_df = pd.read_csv('data/HYSETS_watershed_properties.txt', sep=';', dtype={'Official_ID': str})\n",
    "hysets_df = hysets_df[hysets_df['Source'] == 'HYDAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a centroid shapely Point\n",
    "hysets_df['centroid_geom'] = hysets_df.apply(lambda xy: Point((xy['Centroid_Lon_deg_E'], xy['Centroid_Lat_deg_N'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Watershed_ID', 'Source', 'Name', 'Official_ID', 'Centroid_Lat_deg_N',\n",
       "       'Centroid_Lon_deg_E', 'Drainage_Area_km2', 'Drainage_Area_GSIM_km2',\n",
       "       'Flag_GSIM_boundaries', 'Flag_Artificial_Boundaries', 'Elevation_m',\n",
       "       'Slope_deg', 'Gravelius', 'Perimeter', 'Flag_Shape_Extraction',\n",
       "       'Aspect_deg', 'Flag_Terrain_Extraction', 'Land_Use_Forest_frac',\n",
       "       'Land_Use_Grass_frac', 'Land_Use_Wetland_frac', 'Land_Use_Water_frac',\n",
       "       'Land_Use_Urban_frac', 'Land_Use_Shrubs_frac', 'Land_Use_Crops_frac',\n",
       "       'Land_Use_Snow_Ice_frac', 'Flag_Land_Use_Extraction',\n",
       "       'Permeability_logk_m2', 'Porosity_frac', 'Flag_Subsoil_Extraction',\n",
       "       'centroid_geom'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hysets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of identifying information to facilitate\n",
    "# selection of specific watersheds\n",
    "basin_metadata = ['Watershed_ID', 'Official_ID', 'Name']\n",
    "\n",
    "basin_centroid_geom = ['centroid_geom']\n",
    "\n",
    "basin_characteristics_cols = ['Drainage_Area_km2', \n",
    "                              'Elevation_m', 'Gravelius', 'Aspect_deg', \n",
    "                              'Slope_deg', 'Land_Use_Forest_frac',\n",
    "                              'Land_Use_Grass_frac', 'Land_Use_Wetland_frac', \n",
    "                              'Land_Use_Water_frac', 'Land_Use_Urban_frac', \n",
    "                              'Land_Use_Shrubs_frac', 'Land_Use_Crops_frac',\n",
    "                              'Land_Use_Snow_Ice_frac', 'Permeability_logk_m2', \n",
    "                              'Porosity_frac']\n",
    "\n",
    "hysets_dict = hysets_df[basin_metadata + basin_centroid_geom + basin_characteristics_cols].set_index('Official_ID').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2375 HYDAT station records in the HYSETS database.\n"
     ]
    }
   ],
   "source": [
    "hysets_stns = list(hysets_dict.keys())\n",
    "n_hydat_stns = len(hysets_stns)\n",
    "print(f'There are {n_hydat_stns} HYDAT station records in the HYSETS database.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_pair_in_hysets(pair):\n",
    "    return (pair[0] in hysets_stns) & (pair[1] in hysets_stns)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pair_df = pd.DataFrame(stn_pairs_list, columns=['b1', 'b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t for 6435078 results: 77.2s\n"
     ]
    }
   ],
   "source": [
    "pool = Pool()\n",
    "t0 = time.time()\n",
    "pair_df['pair_in_hysets'] = pool.map(check_if_pair_in_hysets, stn_pairs_list)\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()\n",
    "print(f't for {len(stn_pairs_list)} results: {t1-t0:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len before filter = 6435078\n",
      "len after filter = 529935\n"
     ]
    }
   ],
   "source": [
    "print(f'len before filter = {len(pair_df)}')\n",
    "pair_df = pair_df[pair_df['pair_in_hysets']]\n",
    "print(f'len after filter = {len(pair_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_periods(p):\n",
    "    stn1, stn2 = p[0], p[1]\n",
    "    s1 = df[df['Station Number']==stn1]\n",
    "    s2 = df[df['Station Number']==stn2]\n",
    "    start1, end1 = s1['Year From'].to_numpy()[0], s1['Year To'].to_numpy()[0]\n",
    "    start2, end2 = s2['Year From'].to_numpy()[0], s2['Year To'].to_numpy()[0]\n",
    "    if end1 < end2:\n",
    "        overlap_duration = end1 - start2\n",
    "    else:\n",
    "        overlap_duration = end2 - start1\n",
    "    if overlap_duration > 20:\n",
    "        return p\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to check first pass record overlap: 116.9\n"
     ]
    }
   ],
   "source": [
    "# filter for pairs that have minimum 50 years of concurrent data\n",
    "t0 = time.time()\n",
    "pool = Pool()\n",
    "# overlapping_records = pool.map(check_time_periods, pair_df[['b1', 'b2']].to_numpy())\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()\n",
    "print(f'Time to check first pass record overlap: {t1-t0:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['05AA006', '05AA008'], dtype=object), array(['05AA006', '05AA011'], dtype=object), array(['05AA006', '05AA013'], dtype=object), array(['05AA006', '05AA022'], dtype=object), array(['05AA006', '05AA023'], dtype=object), array(['05AA006', '05AA026'], dtype=object), array(['05AA006', '05AA027'], dtype=object), array(['05AA006', '05AA028'], dtype=object), None, None]\n"
     ]
    }
   ],
   "source": [
    "print(overlapping_records[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = np.array([tuple(e) for e in overlapping_records if e is not None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 229617 unique pairs\n",
      "object type is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f'there are {len(unique_pairs)} unique pairs')\n",
    "print(f'object type is {type(unique_pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1030 unique stations meeting the concurrence criteria.\n"
     ]
    }
   ],
   "source": [
    "unique_concurrent = list(set(unique_pairs.flatten()))\n",
    "num_concurrent = len(unique_concurrent)\n",
    "print(f'there are {num_concurrent} unique stations meeting the concurrence criteria.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the list of unique pairs to disk so you \n",
    "# don't have to go through that process again\n",
    "np.save('unique_pairs.npy', unique_pairs, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the comparative characteristics for each basin pairing\n",
    "\n",
    "1. Calculate a 'similarity' metric based on concurrent data.\n",
    "2. Retrieve basin characteristics from the hysets basin characteristics file.\n",
    "3. Calculate differences in basin elevation, gravelius, drainage area, and distance between basin centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hysets_folder = '/media/danbot/T7 Touch/hysets_series/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_streamflow_series(stn):\n",
    "#     ws = hysets_dict[stn]\n",
    "#     df = ds.sel(watershed=ws['Watershed_ID']-1, drop=True).to_dataframe()\n",
    "    df = pd.read_csv(f'{hysets_folder}{stn}.csv', index_col=['time'])\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_diff(pair, param):\n",
    "    return abs(hysets_dict[pair[0]][param] - hysets_dict[pair[1]][param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_measure_COD(pair):\n",
    "    df1 = extract_streamflow_series(pair[0])\n",
    "    df1.rename(mapper={'discharge': f'{pair[0]}'}, inplace=True, axis=1)\n",
    "    \n",
    "    df2 = extract_streamflow_series(pair[1])\n",
    "    df2.rename(mapper={'discharge': f'{pair[1]}'}, inplace=True, axis=1)\n",
    "    concurrent_df = pd.concat([df1, df2], join='inner', axis=1)\n",
    "    \n",
    "    min_concurrence = 40 * 365\n",
    "    if len(concurrent_df) < min_concurrence:\n",
    "        return None, len(concurrent_df)\n",
    "    \n",
    "    cols = concurrent_df.columns\n",
    "    out = st.linregress(concurrent_df[cols[0]], concurrent_df[cols[1]])    \n",
    "\n",
    "    return out[2]**2, len(concurrent_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(pair):\n",
    "    foo = hysets_df[hysets_df['Official_ID'].isin(pair)]\n",
    "    hdf = gpd.GeoDataFrame(foo, geometry=foo['centroid_geom'], crs='EPSG:4326')\n",
    "    hdf = hdf.to_crs(3005)\n",
    "    hdf.reset_index(inplace=True)\n",
    "    return hdf.loc[0, 'geometry'].distance(hdf.loc[1, 'geometry']) / 1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_similarity_to_distance_calc(pair):\n",
    "    property_diffs = []\n",
    "    similarity, n_days_concurrent = get_similarity_measure_COD(pair)\n",
    "    property_diffs.append(similarity)\n",
    "    property_diffs.append(get_distance(pair))\n",
    "    \n",
    "    for c in basin_characteristics_cols:\n",
    "        property_diffs.append(get_param_diff(pair, c))\n",
    "\n",
    "    if similarity is not None:\n",
    "        return property_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drainage_Area_km2',\n",
       " 'Elevation_m',\n",
       " 'Gravelius',\n",
       " 'Aspect_deg',\n",
       " 'Slope_deg',\n",
       " 'Land_Use_Forest_frac',\n",
       " 'Land_Use_Grass_frac',\n",
       " 'Land_Use_Wetland_frac',\n",
       " 'Land_Use_Water_frac',\n",
       " 'Land_Use_Urban_frac',\n",
       " 'Land_Use_Shrubs_frac',\n",
       " 'Land_Use_Crops_frac',\n",
       " 'Land_Use_Snow_Ice_frac',\n",
       " 'Permeability_logk_m2',\n",
       " 'Porosity_frac']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_characteristics_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results = []\n",
    "# i = 0\n",
    "# t0 = time.time()\n",
    "# for p in unique_pairs_hysets:\n",
    "#     results.append(run_similarity_to_distance_calc(p))\n",
    "#     if (i > 99) & (i % 100 == 0):\n",
    "#         t1 = time.time()\n",
    "#         print(f'time for {i} results: {t1-t0:.1f}')\n",
    "        \n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        b1       b2\n",
      "0  05AA006  05AA008\n",
      "1  05AA006  05AA011\n",
      "2  05AA006  05AA013\n",
      "3  05AA006  05AA022\n",
      "4  05AA006  05AA023\n"
     ]
    }
   ],
   "source": [
    "# load the saved unique pairs\n",
    "unique_pairs_hysets = np.load('unique_pairs.npy').tolist()\n",
    "pairs_df = pd.DataFrame(unique_pairs_hysets)\n",
    "pairs_df.columns = ['b1', 'b2']\n",
    "print(pairs_df.head())\n",
    "# print(f'There are {len(unique_pairs_hysets)} pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pair_properties(row):\n",
    "    for c in basin_characteristics_cols:\n",
    "        p1 = hysets_dict[row['b1']][c]\n",
    "        p2 = hysets_dict[row['b2']][c]\n",
    "    if ~np.isnan(p1) & ~np.isnan(p2):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs_df['char_check'] = pairs_df.apply(lambda row: check_pair_properties(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b1            62170\n",
       "b2            62170\n",
       "char_check    62170\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_df[~pairs_df['char_check']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out pairs missing basin characteristics\n",
    "pairs_df = pairs_df[pairs_df['char_check']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t for 167447 results: 6142.8s\n"
     ]
    }
   ],
   "source": [
    "pool = Pool()\n",
    "t0 = time.time()\n",
    "\n",
    "results = pool.map(run_similarity_to_distance_calc, pairs_df[['b1', 'b2']].to_numpy())\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()\n",
    "print(f't for {len(results)} results: {t1-t0:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167447\n",
      "22152\n"
     ]
    }
   ],
   "source": [
    "# filter out empty result arrays\n",
    "print(len(results))\n",
    "results1 = [e for e in results if e]\n",
    "print(len(results1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results1)\n",
    "results_df.columns = ['similarity', 'distance'] + basin_characteristics_cols\n",
    "results_df\n",
    "results_df.to_csv('results_40y_min1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759\n"
     ]
    }
   ],
   "source": [
    "# char_df['basin_id'] = list(set(pairs_df[['b1', 'b2']].to_numpy().flatten()))\n",
    "filtered_stns = list(set(pairs_df[['b1', 'b2']].to_numpy().flatten()))\n",
    "char_df = hysets_df.loc[hysets_df['Official_ID'].isin(filtered_stns), :].copy()\n",
    "print(len(char_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_df = char_df[[e for e in char_df.columns if 'Centroid' in e] + basin_characteristics_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_df.to_csv('filtered_basins_characteristics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
