{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paired Watershed Characteristics\n",
    "\n",
    "Develop framework to compare pairs of daily flow series from basins in the WSC database.  \n",
    "\n",
    "## Method:\n",
    "\n",
    "1. Generate a list of valid pairs of stations. A valid pair is one where:\n",
    "    * basin geometry exists for both stations\n",
    "    * there is a minimum N years of concurrent data between the two stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basin characteristics\n",
    "WSC_db_folder = '/media/danbot/T7 Touch/hydat_db/'\n",
    "metadata_fn = 'WSC_Stations_Master.csv'\n",
    "\n",
    "df = pd.read_csv(WSC_db_folder + metadata_fn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_years_record'] = df['Year To'] - df['Year From']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for stations in BC and Alberta\n",
    "df = df[df['Province'].isin(['BC', 'AB'])]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_pairs_list = np.random.choice(df['Station Number'].to_numpy(), size=(int(5E6), 2), replace=True)\n",
    "stn_pairs_list = [list(sorted(e)) for e in stn_pairs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stn_pairs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_periods(p):\n",
    "    stn1, stn2 = p[0], p[1]\n",
    "    s1 = df[df['Station Number']==stn1]\n",
    "    s2 = df[df['Station Number']==stn2]\n",
    "    start1, end1 = s1['Year From'].to_numpy()[0], s1['Year To'].to_numpy()[0]\n",
    "    start2, end2 = s2['Year From'].to_numpy()[0], s2['Year To'].to_numpy()[0]\n",
    "    if end1 < end2:\n",
    "        overlap_duration = end1 - start2\n",
    "    else:\n",
    "        overlap_duration = end2 - start1\n",
    "    if overlap_duration > 50:\n",
    "        return p\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for pairs that have minimum 50 years of concurrent data\n",
    "\n",
    "pool = Pool()\n",
    "overlapping_records = pool.map(check_time_periods, stn_pairs_list)\n",
    "pool.close()\n",
    "pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pairs = [e for e in overlapping_records if e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_pairs(pair):\n",
    "    if pair[::-1] not in filtered_pairs:\n",
    "        return pair\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "unique_pairs = pool.map(check_unique_pairs, filtered_pairs)\n",
    "pool.close()\n",
    "pool.join()\n",
    "# unique_pairs = [e for e in filtered_pairs if e[::-1] not in filtered_pairs]\n",
    "print(len(unique_pairs))\n",
    "print(f'Of {len(filtered_pairs)}, {len(unique_pairs)} are unique.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hysets_df = pd.read_csv('data/HYSETS_watershed_properties.txt', sep=';', dtype={'Official_ID': str})\n",
    "print(hysets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a centroid shapely Point\n",
    "hysets_df['centroid_geom'] = hysets_df.apply(lambda xy: Point((xy['Centroid_Lon_deg_E'], xy['Centroid_Lat_deg_N'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hysets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of identifying information to facilitate\n",
    "# selection of specific watersheds\n",
    "basin_metadata = ['Watershed_ID', 'Official_ID', 'Name']\n",
    "\n",
    "basin_centroid_geom = ['centroid_geom']\n",
    "\n",
    "basin_characteristics_cols = ['Drainage_Area_km2', \n",
    "                              'Elevation_m', 'Gravelius', 'Aspect_deg', \n",
    "                              'Slope_deg', 'Land_Use_Forest_frac',\n",
    "                              'Land_Use_Grass_frac', 'Land_Use_Wetland_frac', \n",
    "                              'Land_Use_Water_frac', 'Land_Use_Urban_frac', \n",
    "                              'Land_Use_Shrubs_frac', 'Land_Use_Crops_frac',\n",
    "                              'Land_Use_Snow_Ice_frac', 'Permeability_logk_m2', \n",
    "                              'Porosity_frac']\n",
    "\n",
    "hysets_dict = hysets_df[basin_metadata + basin_centroid_geom + basin_characteristics_cols].set_index('Official_ID').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hysets_folder = '/media/danbot/T7 Touch/hysets_series/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = [p for p in unique_pairs if p]\n",
    "unique_stn_set_from_pairs = list(set([l for sublist in unique_pairs for l in sublist]))\n",
    "unique_stn_set = [e for e in unique_stn_set_from_pairs if e in hysets_dict]\n",
    "print(len(unique_stn_set))\n",
    "unique_stn_set = [e for e in unique_stn_set if ~np.isnan(hysets_dict[e]['Elevation_m'])]\n",
    "print(len(unique_stn_set))\n",
    "print(f'{len(unique_stn_set)} unique stations from the WSC dataset fit the concurrence criteria.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs_hysets = [p for p in unique_pairs if set(p).issubset(unique_stn_set)]\n",
    "    \n",
    "# unique_pairs_hysets = [e for e in unique_pairs if np.in1d(e, unique_stn_set)) == 2]\n",
    "print(f'{len(unique_pairs_hysets)} unique station pairs from the WSC dataset fit the concurrence criteria and are in HYSETS.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_pairs_hysets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the list of unique pairs to disk so you \n",
    "# don't have to go through that process again\n",
    "np.save('unique_pairs.npy', unique_pairs_hysets, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the comparative characteristics for each basin pairing\n",
    "\n",
    "1. Calculate a 'similarity' metric based on concurrent data.\n",
    "2. Retrieve basin characteristics from the hysets basin characteristics file.\n",
    "3. Calculate differences in basin elevation, gravelius, drainage area, and distance between basin centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_streamflow_series(stn):\n",
    "#     ws = hysets_dict[stn]\n",
    "#     df = ds.sel(watershed=ws['Watershed_ID']-1, drop=True).to_dataframe()\n",
    "    df = pd.read_csv(f'{hysets_folder}{stn}.csv', index_col=['time'])\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_diff(pair, param):\n",
    "    return abs(hysets_dict[pair[0]][param] - hysets_dict[pair[1]][param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_measure_COD(pair):\n",
    "    df1 = extract_streamflow_series(pair[0])\n",
    "    df1.rename(mapper={'discharge': f'{pair[0]}'}, inplace=True, axis=1)\n",
    "    \n",
    "    df2 = extract_streamflow_series(pair[1])\n",
    "    df2.rename(mapper={'discharge': f'{pair[1]}'}, inplace=True, axis=1)\n",
    "    concurrent_df = pd.concat([df1, df2], join='inner', axis=1)\n",
    "    \n",
    "    if concurrent_df.empty:\n",
    "        return None\n",
    "    \n",
    "    cols = concurrent_df.columns\n",
    "    out = st.linregress(concurrent_df[cols[0]], concurrent_df[cols[1]])    \n",
    "\n",
    "    return out[2]**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(pair):\n",
    "    foo = hysets_df[hysets_df['Official_ID'].isin(pair)]\n",
    "    hdf = gpd.GeoDataFrame(foo, geometry=foo['centroid_geom'], crs='EPSG:4326')\n",
    "    hdf = hdf.to_crs(3005)\n",
    "    hdf.reset_index(inplace=True)\n",
    "    return hdf.loc[0, 'geometry'].distance(hdf.loc[1, 'geometry']) / 1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_similarity_to_distance_calc(pair):\n",
    "    property_diffs = []\n",
    "    similarity = get_similarity_measure_COD(pair)\n",
    "    property_diffs.append(similarity)\n",
    "    property_diffs.append(get_distance(pair))\n",
    "    \n",
    "    for c in basin_characteristics_cols:\n",
    "        property_diffs.append(get_param_diff(pair, c))\n",
    "\n",
    "    if similarity is not None:\n",
    "        return property_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_characteristics_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results = []\n",
    "# i = 0\n",
    "# t0 = time.time()\n",
    "# for p in unique_pairs_hysets:\n",
    "#     results.append(run_similarity_to_distance_calc(p))\n",
    "#     if (i > 99) & (i % 100 == 0):\n",
    "#         t1 = time.time()\n",
    "#         print(f'time for {i} results: {t1-t0:.1f}')\n",
    "        \n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved unique pairs\n",
    "unique_pairs_hysets = np.load('unique_pairs.npy').tolist()\n",
    "pairs_df = pd.DataFrame(unique_pairs_hysets)\n",
    "pairs_df.columns = ['b1', 'b2']\n",
    "print(pairs_df.head())\n",
    "# print(f'There are {len(unique_pairs_hysets)} pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "t0 = time.time()\n",
    "\n",
    "results = pool.map(run_similarity_to_distance_calc, unique_pairs_hysets)\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()\n",
    "print(f't for {len(results)} results: {t1-t0:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out empty result arrays\n",
    "results = [e for e in results if e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['similarity', 'distance'] + basin_characteristics_cols\n",
    "results_df\n",
    "results_df.to_csv('results1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(results_df.head())\n",
    "# foo = results_df[0]\n",
    "# bar = results_df[1]\n",
    "# print(results_df.max())\n",
    "# print(results_df.min())\n",
    "# sum(np.where(foo > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
