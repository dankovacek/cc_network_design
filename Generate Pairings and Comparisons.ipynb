{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danbot/Documents/code/data_analysis/lib/python3.8/site-packages/geopandas/_compat.py:84: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paired Watershed Characteristics\n",
    "\n",
    "Develop framework to compare pairs of daily flow series from basins in the WSC database.  \n",
    "\n",
    "## Method:\n",
    "\n",
    "1. Generate a list of valid pairs of stations. A valid pair is one where:\n",
    "    * basin geometry exists for both stations\n",
    "    * there is a minimum N years of concurrent data between the two stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station Number</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Province</th>\n",
       "      <th>Status</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Year From</th>\n",
       "      <th>Year To</th>\n",
       "      <th>Gross Drainage Area (km2)</th>\n",
       "      <th>Effective Drainage Area (km2)</th>\n",
       "      <th>...</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Operation Schedule</th>\n",
       "      <th>Sediment</th>\n",
       "      <th>RHBN</th>\n",
       "      <th>Real-Time</th>\n",
       "      <th>Datum Name</th>\n",
       "      <th>Publishing Office</th>\n",
       "      <th>Operating Agency</th>\n",
       "      <th>Contributed</th>\n",
       "      <th>Elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01AA002</td>\n",
       "      <td>DAAQUAM (RIVIERE) EN AVAL DE LA RIVIERE SHIDGEL</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>46.55750</td>\n",
       "      <td>-70.08111</td>\n",
       "      <td>1967</td>\n",
       "      <td>1977</td>\n",
       "      <td>598.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>347.313904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01AA004</td>\n",
       "      <td>GAUTHIER (RIVIERE) A SON EMBOUCHURE</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>46.80083</td>\n",
       "      <td>-70.13806</td>\n",
       "      <td>1975</td>\n",
       "      <td>1981</td>\n",
       "      <td>16.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Level</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01AB001</td>\n",
       "      <td>BUCKLEY (RIVIERE) EN AVAL DU LAC JOHNNY</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>46.87917</td>\n",
       "      <td>-70.08750</td>\n",
       "      <td>1973</td>\n",
       "      <td>1981</td>\n",
       "      <td>6.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Level</td>\n",
       "      <td>Seasonal</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01AD001</td>\n",
       "      <td>MADAWASKA (RIVIÈRE) À 6 KM EN AVAL DU BARRAGE ...</td>\n",
       "      <td>QC</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>47.54833</td>\n",
       "      <td>-68.63639</td>\n",
       "      <td>1918</td>\n",
       "      <td>2005</td>\n",
       "      <td>2690.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>ARBITRAIRE</td>\n",
       "      <td>QUEBEC CITY</td>\n",
       "      <td>MINISTERE DE L'ENVIRONNEMENT DU QUEBEC</td>\n",
       "      <td>Y</td>\n",
       "      <td>143.667770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01AD002</td>\n",
       "      <td>SAINT JOHN RIVER AT FORT KENT</td>\n",
       "      <td>NB</td>\n",
       "      <td>Active</td>\n",
       "      <td>47.25806</td>\n",
       "      <td>-68.59583</td>\n",
       "      <td>1926</td>\n",
       "      <td>2018</td>\n",
       "      <td>14700.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flow</td>\n",
       "      <td>Continuous</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>INTERNATIONAL BOUNDARY COMMISSION DATUM</td>\n",
       "      <td>DARTMOUTH</td>\n",
       "      <td>UNITED STATES GEOLOGICAL SURVEY</td>\n",
       "      <td>Y</td>\n",
       "      <td>158.894211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station Number                                       Station Name Province  \\\n",
       "0        01AA002    DAAQUAM (RIVIERE) EN AVAL DE LA RIVIERE SHIDGEL       QC   \n",
       "1        01AA004                GAUTHIER (RIVIERE) A SON EMBOUCHURE       QC   \n",
       "2        01AB001            BUCKLEY (RIVIERE) EN AVAL DU LAC JOHNNY       QC   \n",
       "3        01AD001  MADAWASKA (RIVIÈRE) À 6 KM EN AVAL DU BARRAGE ...       QC   \n",
       "4        01AD002                      SAINT JOHN RIVER AT FORT KENT       NB   \n",
       "\n",
       "         Status  Latitude  Longitude  Year From  Year To  \\\n",
       "0  Discontinued  46.55750  -70.08111       1967     1977   \n",
       "1  Discontinued  46.80083  -70.13806       1975     1981   \n",
       "2  Discontinued  46.87917  -70.08750       1973     1981   \n",
       "3  Discontinued  47.54833  -68.63639       1918     2005   \n",
       "4        Active  47.25806  -68.59583       1926     2018   \n",
       "\n",
       "   Gross Drainage Area (km2)  Effective Drainage Area (km2)  ... Data Type  \\\n",
       "0                     598.00                            NaN  ...      Flow   \n",
       "1                      16.60                            NaN  ...     Level   \n",
       "2                       6.94                            NaN  ...     Level   \n",
       "3                    2690.00                            NaN  ...      Flow   \n",
       "4                   14700.00                            NaN  ...      Flow   \n",
       "\n",
       "  Operation Schedule Sediment RHBN Real-Time  \\\n",
       "0         Continuous        N    N         N   \n",
       "1           Seasonal        N    N         N   \n",
       "2           Seasonal        N    N         N   \n",
       "3         Continuous        N    N         N   \n",
       "4         Continuous        N    Y         N   \n",
       "\n",
       "                                Datum Name Publishing Office  \\\n",
       "0                               ARBITRAIRE       QUEBEC CITY   \n",
       "1                               ARBITRAIRE       QUEBEC CITY   \n",
       "2                               ARBITRAIRE       QUEBEC CITY   \n",
       "3                               ARBITRAIRE       QUEBEC CITY   \n",
       "4  INTERNATIONAL BOUNDARY COMMISSION DATUM         DARTMOUTH   \n",
       "\n",
       "                         Operating Agency Contributed   Elevation  \n",
       "0  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  347.313904  \n",
       "1  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  401.000000  \n",
       "2  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  411.000000  \n",
       "3  MINISTERE DE L'ENVIRONNEMENT DU QUEBEC           Y  143.667770  \n",
       "4         UNITED STATES GEOLOGICAL SURVEY           Y  158.894211  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import basin characteristics\n",
    "WSC_db_folder = '/media/danbot/T7 Touch/hydat_db/'\n",
    "metadata_fn = 'WSC_Stations_Master.csv'\n",
    "hysets_folder = '/media/danbot/T7 Touch/hysets_series/'\n",
    "camels_folder = '/media/danbot/T7 Touch/camels_db/usgs_streamflow/'\n",
    "\n",
    "df = pd.read_csv(WSC_db_folder + metadata_fn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_years_record'] = df['Year To'] - df['Year From']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588\n"
     ]
    }
   ],
   "source": [
    "# filter for stations in BC and Alberta\n",
    "df = df[df['Province'].isin(['BC', 'AB'])]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588\n",
      "6435078\n"
     ]
    }
   ],
   "source": [
    "# create a list of all pairs of basins in the hydat database\n",
    "hydat_stn_pairs_list = list(combinations(df['Station Number'].to_numpy(), 2))\n",
    "\n",
    "print(len(df))\n",
    "print(len(stn_pairs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all camels files \n",
    "camels_files, camels_files_stations = [], []\n",
    "for f in os.listdir(camels_folder):\n",
    "    camels_files += [camels_folder + f + '/' + e for e in os.listdir(camels_folder + f)]\n",
    "    camels_files_stations += [e.split('_')[0] for e in os.listdir(camels_folder + f)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hysets_df = pd.read_csv('data/HYSETS_watershed_properties.txt', sep=';', dtype={'Official_ID': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the HYDAT subset\n",
    "hydat_df = hysets_df[hysets_df['Source'] == 'HYDAT'].copy()\n",
    "# extract the USGS subset\n",
    "usgs_df = hysets_df[hysets_df['Source'] == 'USGS'].copy()\n",
    "# extract the Mexico subset\n",
    "mex_df = hysets_df[hysets_df['Source'] == 'Mexico'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a centroid shapely Point\n",
    "hydat_df['centroid_geom'] = hydat_df.apply(lambda xy: Point((xy['Centroid_Lon_deg_E'], xy['Centroid_Lat_deg_N'])), axis=1)\n",
    "usgs_df['centroid_geom'] = usgs_df.apply(lambda xy: Point((xy['Centroid_Lon_deg_E'], xy['Centroid_Lat_deg_N'])), axis=1)\n",
    "mex_df['centroid_geom'] = mex_df.apply(lambda xy: Point((xy['Centroid_Lon_deg_E'], xy['Centroid_Lat_deg_N'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the common columns between all subsets of HYSETS basins\n",
    "usgs_hydat_columns = np.intersect1d(hydat_df.columns, usgs_df.columns)\n",
    "all_common_cols = np.intersect1d(usgs_hydat_columns, mex_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of identifying information to facilitate\n",
    "# selection of specific watersheds\n",
    "basin_metadata = ['Watershed_ID', 'Official_ID', 'Name']\n",
    "\n",
    "basin_centroid_geom = ['centroid_geom']\n",
    "\n",
    "basin_characteristics_cols = ['Centroid_Lat_deg_N', 'Centroid_Lon_deg_E',\n",
    "              'Drainage_Area_GSIM_km2', 'Drainage_Area_km2',\n",
    "              'Elevation_m', 'Gravelius', 'Perimeter', 'Slope_deg', 'Aspect_deg', \n",
    "              'Land_Use_Crops_frac', 'Land_Use_Forest_frac', 'Land_Use_Grass_frac',\n",
    "              'Land_Use_Shrubs_frac', 'Land_Use_Snow_Ice_frac', 'Land_Use_Urban_frac',\n",
    "              'Land_Use_Water_frac', 'Land_Use_Wetland_frac', \n",
    "              'Permeability_logk_m2', 'Porosity_frac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydat_dict = hydat_df[basin_metadata + basin_centroid_geom + basin_characteristics_cols].set_index('Official_ID').to_dict(orient='index')\n",
    "usgs_dict = usgs_df[basin_metadata + basin_centroid_geom + basin_characteristics_cols].set_index('Official_ID').to_dict(orient='index')\n",
    "mex_dict = mex_df[basin_metadata + basin_centroid_geom + basin_characteristics_cols].set_index('Official_ID').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usgs_stns[:10]\n",
    "# fix the station numbering zero padding convention in the usgs set from hysets\n",
    "usgs_stns = []\n",
    "for f in usgs_dict.keys():\n",
    "    if len(f) == 8:\n",
    "        usgs_stns.append(f)\n",
    "    elif f[0] == '0':\n",
    "        s = f[1:]\n",
    "        if s[0] == '0':\n",
    "            s = s[1:]\n",
    "            if s[0] == '0':\n",
    "                s = s[1:]\n",
    "        if len(s) == 8:\n",
    "            usgs_stns.append(s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all station IDs common to HYSETS and CAMELS\n",
    "camels_stns = np.intersect1d(usgs_stns, camels_files_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2375 HYDAT station records in the HYSETS database.\n",
      "There are 645 CAMELS station records in the HYSETS database.\n",
      "There are 46 Mexico station records in the HYSETS database.\n"
     ]
    }
   ],
   "source": [
    "hydat_stns, mex_stns = list(hydat_dict.keys()), list(mex_dict.keys())\n",
    "# filter the usgs list for just the stations in CAMELS\n",
    "print(f'There are {len(hydat_stns)} HYDAT station records in the HYSETS database.')\n",
    "print(f'There are {len(camels_stns)} CAMELS station records in the HYSETS database.')\n",
    "print(f'There are {len(mex_stns)} Mexico station records in the HYSETS database.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydat_stn_pairs_list = list(combinations(hydat_stns, 2))\n",
    "camels_stn_pairs_list = list(combinations(camels_stns, 2))\n",
    "mex_stn_pairs_list = list(combinations(mex_stns, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hydat_pair_df = pd.DataFrame(hydat_stn_pairs_list, columns=['b1', 'b2'])\n",
    "camels_pair_df = pd.DataFrame(camels_stn_pairs_list, columns=['b1', 'b2'])\n",
    "mex_pair_df = pd.DataFrame(mex_stn_pairs_list, columns=['b1', 'b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_properties_dict = {'hydat': hydat_dict,\n",
    "                      'camels': usgs_dict,\n",
    "                       'mex': mex_dict,\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pair_properties(p, basin_dict):\n",
    "    \"\"\"\n",
    "    Check if \n",
    "    \"\"\"\n",
    "    for c in basin_characteristics_cols:\n",
    "        p1 = all_properties_dict[basin_dict][p['b1']][c]\n",
    "        p2 = all_properties_dict[basin_dict][p['b2']][c]\n",
    "    if ~np.isnan(p1) & ~np.isnan(p2):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mex_pair_df['char_check'] = mex_pair_df.apply(lambda row: check_pair_properties(row, 'mex'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "camels_pair_df['char_check'] = camels_pair_df.apply(lambda row: check_pair_properties(row, 'camels'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydat_pair_df['char_check'] = hydat_pair_df.apply(lambda row: check_pair_properties(row, 'hydat'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 basins in hydat have missing characteristics\n",
      "3 basins in camels have missing characteristics\n",
      "3 basins in Mexico have missing characteristics\n"
     ]
    }
   ],
   "source": [
    "missing_characteristics = hydat_pair_df[~hydat_pair_df['char_check']].count()\n",
    "print(f'{len(missing_characteristics)} basins in hydat have missing characteristics')\n",
    "missing_characteristics = camels_pair_df[~camels_pair_df['char_check']].count()\n",
    "print(f'{len(missing_characteristics)} basins in camels have missing characteristics')\n",
    "missing_characteristics = mex_pair_df[~mex_pair_df['char_check']].count()\n",
    "print(f'{len(missing_characteristics)} basins in Mexico have missing characteristics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out pairs missing basin characteristics\n",
    "hydat_pair_df = hydat_pair_df[hydat_pair_df['char_check']]\n",
    "camels_pair_df = camels_pair_df[camels_pair_df['char_check']]\n",
    "mex_pair_df = mex_pair_df[mex_pair_df['char_check']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_streamflow_series(stn):\n",
    "#     ws = hysets_dict[stn]\n",
    "#     df = ds.sel(watershed=ws['Watershed_ID']-1, drop=True).to_dataframe()\n",
    "    df = pd.read_csv(f'{hysets_folder}{stn}.csv', index_col=['time'])\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_concurrence_len(pair):\n",
    "    df1 = extract_streamflow_series(pair[0])\n",
    "    df1.rename(mapper={'discharge': f'{pair[0]}'}, inplace=True, axis=1)\n",
    "    \n",
    "    df2 = extract_streamflow_series(pair[1])\n",
    "    df2.rename(mapper={'discharge': f'{pair[1]}'}, inplace=True, axis=1)\n",
    "    concurrent_df = pd.concat([df1, df2], join='inner', axis=1)\n",
    "    return len(concurrent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to calculate concurrent period lengths: 10.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "pool = Pool()\n",
    "\n",
    "# pair_df['concurrence_check'] = pool.map(check_actual_concurrence_len, pair_df[['b1', 'b2']].to_numpy()[:10])\n",
    "mex_pair_df['concurrent_days'] = pool.map(check_actual_concurrence_len, \n",
    "               mex_pair_df[['b1', 'b2']].to_numpy())\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()\n",
    "print(f'Time to calculate concurrent period lengths: {t1 - t0:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to calculate concurrent period lengths: 2616.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "pool = Pool()\n",
    "\n",
    "# pair_df['concurrence_check'] = pool.map(check_actual_concurrence_len, pair_df[['b1', 'b2']].to_numpy()[:10])\n",
    "camels_pair_df['concurrent_days'] = pool.map(check_actual_concurrence_len, \n",
    "               camels_pair_df[['b1', 'b2']].to_numpy())\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()\n",
    "print(f'Time to calculate concurrent period lengths: {t1 - t0:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to calculate concurrent period lengths: 12141.6\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "pool = Pool()\n",
    "\n",
    "# pair_df['concurrence_check'] = pool.map(check_actual_concurrence_len, pair_df[['b1', 'b2']].to_numpy()[:10])\n",
    "hydat_pair_df['concurrent_days'] = pool.map(check_actual_concurrence_len, \n",
    "               hydat_pair_df[['b1', 'b2']].to_numpy())\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()\n",
    "print(f'Time to calculate concurrent period lengths: {t1 - t0:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        b1       b2  char_check  concurrent_days\n",
      "0  01AD002  01AD003        True            23103\n",
      "1  01AD002  01AD015        True             1131\n",
      "2  01AD002  01AE001        True            12418\n",
      "4  01AD002  01AF007        True            13879\n",
      "5  01AD002  01AF009        True             8766\n",
      "         b1        b2  char_check  concurrent_days\n",
      "0  01013500  01022500        True            25202\n",
      "1  01013500  01030500        True            25202\n",
      "2  01013500  01031500        True            25202\n",
      "3  01013500  01047000        True            25202\n",
      "4  01013500  01052500        True              806\n",
      "      b1     b2  char_check  concurrent_days\n",
      "0  10034  10063        True             2039\n",
      "1  10034  11027        True             8729\n",
      "2  10034  11040        True             8729\n",
      "3  10034  12238        True            11284\n",
      "4  10034  12370        True            13474\n",
      "1826916\n",
      "205761\n",
      "1035\n"
     ]
    }
   ],
   "source": [
    "print(hydat_pair_df.head())\n",
    "print(camels_pair_df.head())\n",
    "print(mex_pair_df.head())\n",
    "print(len(hydat_pair_df))\n",
    "print(len(camels_pair_df))\n",
    "print(len(mex_pair_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1436232 HYDAT basin pairs meet the concurrence length criteria.\n",
      "205667 CAMELS basin pairs meet the concurrence length criteria.\n",
      "969 Mexico basin pairs meet the concurrence length criteria.\n"
     ]
    }
   ],
   "source": [
    "hydat_pair_df = hydat_pair_df[hydat_pair_df['concurrent_days'] > 365]\n",
    "print(f'{len(hydat_pair_df)} HYDAT basin pairs meet the concurrence length criteria.')\n",
    "camels_pair_df = camels_pair_df[camels_pair_df['concurrent_days'] > 365]\n",
    "print(f'{len(camels_pair_df)} CAMELS basin pairs meet the concurrence length criteria.')\n",
    "mex_pair_df = mex_pair_df[mex_pair_df['concurrent_days'] > 365]\n",
    "print(f'{len(mex_pair_df)} Mexico basin pairs meet the concurrence length criteria.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the list of unique pairs to disk so you \n",
    "# don't have to go through that process again\n",
    "hydat_pair_df.to_pickle('results/filtered_pairs_HYDAT_all_concurrent_lengths.csv')\n",
    "camels_pair_df.to_pickle('results/filtered_pairs_CAMELS_all_concurrent_lengths.csv')\n",
    "mex_pair_df.to_pickle('results/filtered_pairs_MEX_all_concurrent_lengths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('01543500', '06910800'), ('02235200', '06614800'), ('03164000', '06406000'), ('03140000', '06224000'), ('02350900', '05488200')]\n",
      "205667\n"
     ]
    }
   ],
   "source": [
    "filtered_pairs = camels_pair_df[['b1', 'b2']].to_numpy()\n",
    "filtered_pairs = [tuple(e) for e in filtered_pairs]\n",
    "unique_concurrent = list(set(filtered_pairs))\n",
    "print(unique_concurrent[:5])\n",
    "print(len(unique_concurrent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Load all Saved Results\n",
    "\n",
    "Continue the distance metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = pd.read_pickle('results/filtered_pairs_HYSETS_all_concurrent_lengths.csv')\n",
    "all_df = pd.read_pickle('results/filtered_pairs_CAMELS_all_concurrent_lengths.csv')\n",
    "all_df = all_df[['b1', 'b2', 'concurrent_days']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run similarity operation on filtered pairs\n",
    "\n",
    "1. Calculate a 'similarity' metric based on concurrent data.\n",
    "2. Retrieve basin characteristics from the hysets basin characteristics file.\n",
    "3. Calculate differences in basin elevation, gravelius, drainage area, and distance between basin centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_diff(pair, param):\n",
    "    return hysets_dict[pair[0]][param] - hysets_dict[pair[1]][param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(pair):\n",
    "    foo = camels_df[hysets_df['Official_ID'].isin(pair)]\n",
    "    hdf = gpd.GeoDataFrame(foo, geometry=foo['centroid_geom'], crs='EPSG:4326')\n",
    "    hdf = hdf.to_crs(3005)\n",
    "    hdf.reset_index(inplace=True)\n",
    "    return hdf.loc[0, 'geometry'].distance(hdf.loc[1, 'geometry']) / 1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry as geom\n",
    "\n",
    "def create_line(row):\n",
    "    return geom.LineString([usgs_dict[row['b1']]['centroid_geom'], usgs_dict[row['b2']]['centroid_geom']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>centroid_distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINESTRING (4902150.132 1922495.212, 5148214.2...</td>\n",
       "      <td>294.705205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LINESTRING (4902150.132 1922495.212, 5056283.6...</td>\n",
       "      <td>193.111443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINESTRING (4902150.132 1922495.212, 5027205.5...</td>\n",
       "      <td>234.857685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LINESTRING (4902150.132 1922495.212, 5015698.1...</td>\n",
       "      <td>282.558269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINESTRING (4902150.132 1922495.212, 4952812.5...</td>\n",
       "      <td>324.124451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  centroid_distance_km\n",
       "0  LINESTRING (4902150.132 1922495.212, 5148214.2...            294.705205\n",
       "1  LINESTRING (4902150.132 1922495.212, 5056283.6...            193.111443\n",
       "2  LINESTRING (4902150.132 1922495.212, 5027205.5...            234.857685\n",
       "3  LINESTRING (4902150.132 1922495.212, 5015698.1...            282.558269\n",
       "4  LINESTRING (4902150.132 1922495.212, 4952812.5...            324.124451"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def set_centroid_geom()\n",
    "\n",
    "# all_df['centroids'] = all_df.apply(row: Point(xy) for xy in )\n",
    "geometry = gpd.GeoDataFrame({'geometry': all_df.apply(lambda row: create_line(row), axis=1)}, crs='EPSG:4326')\n",
    "\n",
    "geometry = geometry.to_crs(3005)\n",
    "geometry['centroid_distance_km'] = geometry.length / 1000  # convert to km\n",
    "geometry.head()\n",
    "# all_df.head()\n",
    "\n",
    "# all_df['b1'].apply(lambda e: hysets_dict[e]['centroid_geom']) \n",
    "# all_df['b2_centroid_geom'] = all_df['b2'].apply(lambda e: hysets_dict[e]['centroid_geom']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>concurrent_days</th>\n",
       "      <th>distance_btwn_centroids_km</th>\n",
       "      <th>pair_midpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01013500</td>\n",
       "      <td>01022500</td>\n",
       "      <td>25202</td>\n",
       "      <td>294.705205</td>\n",
       "      <td>POINT (4902150.549 1922494.936)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01013500</td>\n",
       "      <td>01030500</td>\n",
       "      <td>25202</td>\n",
       "      <td>193.111443</td>\n",
       "      <td>POINT (4902150.531 1922494.910)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01013500</td>\n",
       "      <td>01031500</td>\n",
       "      <td>25202</td>\n",
       "      <td>234.857685</td>\n",
       "      <td>POINT (4902150.398 1922494.788)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01013500</td>\n",
       "      <td>01047000</td>\n",
       "      <td>25202</td>\n",
       "      <td>282.558269</td>\n",
       "      <td>POINT (4902150.333 1922494.754)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01013500</td>\n",
       "      <td>01052500</td>\n",
       "      <td>806</td>\n",
       "      <td>324.124451</td>\n",
       "      <td>POINT (4902150.210 1922494.718)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         b1        b2  concurrent_days  distance_btwn_centroids_km  \\\n",
       "0  01013500  01022500            25202                  294.705205   \n",
       "1  01013500  01030500            25202                  193.111443   \n",
       "2  01013500  01031500            25202                  234.857685   \n",
       "3  01013500  01047000            25202                  282.558269   \n",
       "4  01013500  01052500              806                  324.124451   \n",
       "\n",
       "                     pair_midpoint  \n",
       "0  POINT (4902150.549 1922494.936)  \n",
       "1  POINT (4902150.531 1922494.910)  \n",
       "2  POINT (4902150.398 1922494.788)  \n",
       "3  POINT (4902150.333 1922494.754)  \n",
       "4  POINT (4902150.210 1922494.718)  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['distance_btwn_centroids_km'] = geometry['centroid_distance_km']\n",
    "\n",
    "all_df['pair_midpoint'] = geometry['geometry'].interpolate(0.5, normalized=False)\n",
    "\n",
    "all_df.head()\n",
    "# print(hysets_dict['05AA006'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_df['normed_distance'] = (pair_df['PC_distance'] - pair_df['PC_distance'].min()) / (pair_df['PC_distance'].max() - pair_df['PC_distance'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-bd48273f88e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4326\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'midpoint_lat_deg_N'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'midpoint_lon_deg_E'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/data_analysis/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7546\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7547\u001b[0m         )\n\u001b[0;32m-> 7548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/data_analysis/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/data_analysis/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/data_analysis/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-bd48273f88e9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(mp)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4326\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'midpoint_lat_deg_N'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'midpoint_lon_deg_E'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/data_analysis/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'y'"
     ]
    }
   ],
   "source": [
    "# foo = all_df.copy()\n",
    "# convert back to EPSG 4326 for saving geographic coordinates\n",
    "geometry = geometry.to_crs(4326)\n",
    "\n",
    "all_df['midpoint_lat_deg_N'] = midpoint.apply(lambda mp: mp.y)\n",
    "all_df['midpoint_lon_deg_E'] = midpoint.apply(lambda mp: mp.x)\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_measure_COD(pair):\n",
    "    df1 = extract_streamflow_series(pair[0])    \n",
    "    df2 = extract_streamflow_series(pair[1])\n",
    "\n",
    "    concurrent_df = pd.concat([df1, df2], join='inner', axis=1)\n",
    "    if len(concurrent_df) >= 365:\n",
    "        cols = concurrent_df.columns\n",
    "        out = st.linregress(concurrent_df.to_numpy())    \n",
    "\n",
    "        return out[2]**2\n",
    "    else:\n",
    "        return np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_characteristics_cols\n",
    "for char in basin_characteristics_cols:\n",
    "#     b1_char = \n",
    "    all_df[f'{char}_diff'] = [usgs_dict[b1][char] - usgs_dict[b2][char] for b1, b2 in all_df[['b1', 'b2']].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool = Pool()\n",
    "t0 = time.time()\n",
    "all_df['similarity'] = pool.map(calculate_similarity_measure_COD, all_df[['b1', 'b2']].to_numpy())\n",
    "pool.close()\n",
    "pool.join()\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t for 205667 results: 2724.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['b1', 'b2', 'concurrent_days', 'distance_btwn_centroids_km',\n",
       "       'pair_midpoint', 'Centroid_Lat_deg_N_diff', 'Centroid_Lon_deg_E_diff',\n",
       "       'Drainage_Area_GSIM_km2_diff', 'Drainage_Area_km2_diff',\n",
       "       'Elevation_m_diff', 'Gravelius_diff', 'Perimeter_diff',\n",
       "       'Slope_deg_diff', 'Aspect_deg_diff', 'Land_Use_Crops_frac_diff',\n",
       "       'Land_Use_Forest_frac_diff', 'Land_Use_Grass_frac_diff',\n",
       "       'Land_Use_Shrubs_frac_diff', 'Land_Use_Snow_Ice_frac_diff',\n",
       "       'Land_Use_Urban_frac_diff', 'Land_Use_Water_frac_diff',\n",
       "       'Land_Use_Wetland_frac_diff', 'Permeability_logk_m2_diff',\n",
       "       'Porosity_frac_diff', 'similarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f't for {len(all_df)} results: {t1-t0:.1f}s')\n",
    "all_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205667\n",
      "205667\n"
     ]
    }
   ],
   "source": [
    "results_df = all_df.copy()\n",
    "print(len(results_df))\n",
    "results_df.dropna(subset=['similarity'], inplace=True)\n",
    "print(len(results_df))\n",
    "hydat_fp = 'results/results_HYDAT_min_365d_concurrent.csv'\n",
    "camels_fp = 'results/results_CAMELS_min_365d_concurrent.csv'\n",
    "mex_fp = 'results/results_MEX_min_365d_concurrent.csv'\n",
    "results_df.to_csv(camels_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "foo = pd.read_csv('results/results_CAMELS_min_365d_concurrent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b1                             0\n",
       "b2                             0\n",
       "concurrent_days                0\n",
       "distance_btwn_centroids_km     0\n",
       "pair_midpoint                  0\n",
       "Centroid_Lat_deg_N_diff        0\n",
       "Centroid_Lon_deg_E_diff        0\n",
       "Drainage_Area_GSIM_km2_diff    0\n",
       "Drainage_Area_km2_diff         0\n",
       "Elevation_m_diff               0\n",
       "Gravelius_diff                 0\n",
       "Perimeter_diff                 0\n",
       "Slope_deg_diff                 0\n",
       "Aspect_deg_diff                0\n",
       "Land_Use_Crops_frac_diff       0\n",
       "Land_Use_Forest_frac_diff      0\n",
       "Land_Use_Grass_frac_diff       0\n",
       "Land_Use_Shrubs_frac_diff      0\n",
       "Land_Use_Snow_Ice_frac_diff    0\n",
       "Land_Use_Urban_frac_diff       0\n",
       "Land_Use_Water_frac_diff       0\n",
       "Land_Use_Wetland_frac_diff     0\n",
       "Permeability_logk_m2_diff      0\n",
       "Porosity_frac_diff             0\n",
       "similarity                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[foo['similarity'].isna()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
